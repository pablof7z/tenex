#!/usr/bin/env bun
import path from "path";
import { NDKEvent } from "@nostr-dev-kit/ndk";
import chalk from "chalk";
import fs from "fs/promises";
import { getNDK } from "./src/nostr/ndkClient";
import { Agent } from "./src/utils/agents/Agent";
import { AgentManager } from "./src/utils/agents/AgentManager";
import { logger } from "./src/utils/logger";

async function createTestProject() {
	const testProjectPath = path.join(process.cwd(), "test-agent-project");

	// Create test project structure
	await fs.mkdir(path.join(testProjectPath, ".tenex"), { recursive: true });

	// Create metadata.json
	await fs.writeFile(
		path.join(testProjectPath, ".tenex", "metadata.json"),
		JSON.stringify(
			{
				name: "Test Agent Project",
				title: "Test Agent Project",
				projectNaddr: "naddr1qqqqqqqqtest",
			},
			null,
			2,
		),
	);

	// Create agents.json with valid test nsecs (these are just for testing)
	// In real usage, these would be generated by NDKPrivateKeySigner.generate()
	await fs.writeFile(
		path.join(testProjectPath, ".tenex", "agents.json"),
		JSON.stringify(
			{
				default:
					"nsec1vl029mgpspedva04g90vltkh6fvh240zqtv9k0t9af8935ke9laqsnlfe5",
				coder:
					"nsec10allq0gjx7fddtzef0ax00mdps9t2kmtrldkyjfs8l5xruwvh2dq0lhhkp",
			},
			null,
			2,
		),
	);

	// Create llms.json with test configurations
	await fs.writeFile(
		path.join(testProjectPath, ".tenex", "llms.json"),
		JSON.stringify(
			{
				default: "test-llm",
				"test-llm": {
					provider: "openai",
					model: "gpt-3.5-turbo",
					apiKey: "test-api-key",
					temperature: 0.7,
				},
				"anthropic-test": {
					provider: "anthropic",
					model: "claude-3-opus-20240229",
					apiKey: "test-anthropic-key",
				},
			},
			null,
			2,
		),
	);

	// Create agent configurations
	await fs.mkdir(path.join(testProjectPath, ".tenex", "agents"), {
		recursive: true,
	});

	await fs.writeFile(
		path.join(testProjectPath, ".tenex", "agents", "default.json"),
		JSON.stringify(
			{
				name: "default",
				description: "Default project assistant",
				role: "a helpful AI assistant",
				instructions:
					"Help users with their requests in a friendly and professional manner.",
			},
			null,
			2,
		),
	);

	await fs.writeFile(
		path.join(testProjectPath, ".tenex", "agents", "coder.json"),
		JSON.stringify(
			{
				name: "coder",
				description: "Expert coding assistant",
				role: "an expert software developer",
				instructions:
					"Provide high-quality code solutions and technical guidance.",
				systemPrompt:
					"You are an expert coder. Focus on clean, efficient, and well-documented code.",
			},
			null,
			2,
		),
	);

	return testProjectPath;
}

async function testAgentManager() {
	console.log(chalk.blue("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"));
	console.log(chalk.cyan("🧪 Testing Agent Manager"));
	console.log(chalk.blue("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n"));

	const projectPath = await createTestProject();

	try {
		// Initialize agent manager
		console.log(chalk.yellow("1. Initializing Agent Manager..."));
		const agentManager = new AgentManager(projectPath);
		await agentManager.initialize();
		console.log(chalk.green("✓ Agent Manager initialized\n"));

		// Test loading agents
		console.log(chalk.yellow("2. Testing agent loading..."));
		const defaultAgent = await agentManager.getAgent("default");
		console.log(chalk.green("✓ Default agent loaded"));
		console.log(chalk.gray(`   Name: ${defaultAgent.getName()}`));
		console.log(
			chalk.gray(
				`   System prompt preview: ${defaultAgent.getSystemPrompt().substring(0, 100)}...`,
			),
		);

		const coderAgent = await agentManager.getAgent("coder");
		console.log(chalk.green("✓ Coder agent loaded"));
		console.log(chalk.gray(`   Name: ${coderAgent.getName()}`));
		console.log(
			chalk.gray(`   System prompt: ${coderAgent.getSystemPrompt()}\n`),
		);

		// Test LLM configurations
		console.log(chalk.yellow("3. Testing LLM configurations..."));
		const llmConfigs = agentManager.getAllLLMConfigs();
		console.log(chalk.green(`✓ Loaded ${llmConfigs.size} LLM configurations`));
		for (const [name, config] of llmConfigs) {
			console.log(
				chalk.gray(`   - ${name}: ${config.provider}/${config.model}`),
			);
		}

		const defaultLLM = agentManager.getLLMConfig();
		console.log(
			chalk.green(
				`✓ Default LLM: ${defaultLLM?.provider}/${defaultLLM?.model}\n`,
			),
		);

		// Test conversation management
		console.log(chalk.yellow("4. Testing conversation management..."));
		const conversation = defaultAgent.createConversation("test-conv-1");
		console.log(chalk.green("✓ Created conversation"));

		conversation.addUserMessage("Hello, how are you?");
		conversation.addAssistantMessage(
			"I'm doing well, thank you! How can I help you today?",
		);

		const messages = conversation.getMessages();
		console.log(chalk.green(`✓ Conversation has ${messages.length} messages`));
		messages.forEach((msg, i) => {
			console.log(
				chalk.gray(`   [${i}] ${msg.role}: ${msg.content.substring(0, 50)}...`),
			);
		});
		console.log();

		// Test creating new agent on the fly
		console.log(chalk.yellow("5. Testing dynamic agent creation..."));
		const newAgent = await agentManager.getAgent("planner");
		console.log(chalk.green("✓ Created new agent 'planner' dynamically"));
		console.log(chalk.gray(`   Name: ${newAgent.getName()}\n`));

		// Test event handling simulation
		console.log(chalk.yellow("6. Testing event handling (simulation)..."));
		const ndk = await getNDK();

		// Create mock chat event
		const chatEvent = new NDKEvent(ndk);
		chatEvent.kind = 11;
		chatEvent.content = "What is the weather like today?";
		chatEvent.id = "test-chat-event-1";
		chatEvent.author = { pubkey: "test-pubkey" } as any;
		chatEvent.tags = [];

		console.log(chalk.gray("   Created mock chat event"));
		console.log(
			chalk.gray("   Note: Actual LLM calls will fail without valid API keys"),
		);

		// Clean up
		await fs.rm(projectPath, { recursive: true });
		console.log(chalk.green("\n✓ Test completed successfully!"));
	} catch (error: any) {
		console.error(chalk.red("\n❌ Test failed:"));
		console.error(chalk.red(error.message));
		console.error(chalk.gray(error.stack));
		// Clean up on error
		await fs.rm(projectPath, { recursive: true }).catch(() => {});
	}
}

async function testAgentResponse() {
	console.log(chalk.blue("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"));
	console.log(chalk.cyan("🤖 Testing Agent Response Generation"));
	console.log(chalk.blue("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n"));

	const projectPath = await createTestProject();

	try {
		// Create a simple agent with a valid nsec
		const agent = new Agent(
			"test-agent",
			"nsec1vl029mgpspedva04g90vltkh6fvh240zqtv9k0t9af8935ke9laqsnlfe5",
			{
				name: "test-agent",
				role: "a helpful assistant",
				instructions: "Be concise and helpful",
			},
		);

		// Set up a mock LLM config (will fail without real API key)
		agent.setDefaultLLMConfig({
			provider: "openai",
			model: "gpt-3.5-turbo",
			apiKey: "test-key",
		});

		// Create conversation
		const conversation = agent.createConversation("test-response");
		conversation.addUserMessage("What is 2+2?");

		console.log(chalk.yellow("Agent conversation set up with test message"));
		console.log(
			chalk.gray("Note: Response generation will fail without valid API key"),
		);
		console.log(
			chalk.gray("This is expected and demonstrates the system structure\n"),
		);

		// Clean up
		await fs.rm(projectPath, { recursive: true });
	} catch (error: any) {
		console.error(chalk.red("\n❌ Test failed:"));
		console.error(chalk.red(error.message));
		await fs.rm(projectPath, { recursive: true }).catch(() => {});
	}
}

// Run tests
async function main() {
	await testAgentManager();
	await testAgentResponse();

	console.log(chalk.blue("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"));
	console.log(chalk.green("🎉 All tests completed!"));
	console.log(chalk.blue("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n"));

	process.exit(0);
}

main().catch((error) => {
	logger.error("Fatal error:", error);
	process.exit(1);
});
